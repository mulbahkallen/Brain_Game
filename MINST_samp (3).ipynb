{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "MINST_samp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKdZlT3f3OqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ53E5cyOjcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbZmaLW_3OqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Unit(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super(Unit,self).__init__()\n",
        "        \n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,kernel_size=3,out_channels=out_channels,stride=1,padding=1)\n",
        "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,input):\n",
        "        output = self.conv(input)\n",
        "        output = self.bn(output)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(SimpleNet,self).__init__()\n",
        "        \n",
        "        #Create 14 layers of the unit with max pooling in between\n",
        "        self.unit1 = Unit(in_channels=3,out_channels=32)\n",
        "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
        "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
        "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit7 = Unit(in_channels=64, out_channels=64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit8 = Unit(in_channels=64, out_channels=128)\n",
        "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit11 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit12 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
        "        \n",
        "        #  make fc a sequential layer and add within softmax and linear \n",
        "\n",
        "        #Add all the units into the Sequential layer in exact order\n",
        "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6\n",
        "                                 ,self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
        "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
        "\n",
        "        self.fc = nn.Linear(in_features=128,out_features=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.net(input)\n",
        "        output = output.view(-1,128)\n",
        "        output = self.fc(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ5x9Zsg3OqY",
        "colab_type": "code",
        "outputId": "20c9852a-ea08-4e2b-8a56-cd1174129831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Define transformations for the training set, flip the images randomly, crop out and apply mean and std normalization\n",
        "train_transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32,padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "#Load the training set\n",
        "train_set =CIFAR10(root=\"./data\",train=True,transform=train_transformations,download=True)\n",
        "\n",
        "#Create a loder for the training set\n",
        "train_loader = DataLoader(train_set,batch_size=32,shuffle=True,num_workers=4)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 27840548.76it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZx5oaJk3Oqb",
        "colab_type": "code",
        "outputId": "b7fe4308-bf2e-4429-a995-e99ee568af5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define transformations for the test set\n",
        "test_transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "])\n",
        "\n",
        "# Load the test set, note that train is set to False\n",
        "test_set = CIFAR10(root=\"./data\", train=False, transform=test_transformations, download=True)\n",
        "\n",
        "# Create a loder for the test set, note that both shuffle is set to false for the test loader\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM5vbiSb3Oqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "# Check if gpu support is available\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "\n",
        "# Create model, optimizer and loss function\n",
        "model = SimpleNet(num_classes=10)\n",
        "\n",
        "#if cuda is available, move the model to the GPU\n",
        "if cuda_avail:\n",
        "    model.cuda()\n",
        "\n",
        "#Define the optimizer and loss function\n",
        "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX6IHBm03Oqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust_learning_rate(epoch):\n",
        "    lr = 0.001\n",
        "\n",
        "    if epoch > 180:\n",
        "        lr = lr / 1000000\n",
        "    elif epoch > 150:\n",
        "        lr = lr / 100000\n",
        "    elif epoch > 120:\n",
        "        lr = lr / 10000\n",
        "    elif epoch > 90:\n",
        "        lr = lr / 1000\n",
        "    elif epoch > 60:\n",
        "        lr = lr / 100\n",
        "    elif epoch > 30:\n",
        "        lr = lr / 10\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1p_-Dtu3Oqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_models(epoch):\n",
        "    torch.save(model.state_dict(), \"cifar10model_{}.model\".format(epoch))\n",
        "    print(\"Chekcpoint saved\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZXmVNs-3Oqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_acc = 0.0\n",
        "    for i, (images, labels) in enumerate(test_loader):\n",
        "\n",
        "        if cuda_avail:\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "\n",
        "        # Predict classes using images from the test set\n",
        "        outputs = model(images)\n",
        "        _, prediction = torch.max(outputs.data, 1)\n",
        "        \n",
        "        test_acc += torch.sum(prediction == labels.data)\n",
        "\n",
        "    # Compute the average acc and loss over all 10000 test images\n",
        "    test_acc = test_acc / 10000\n",
        "\n",
        "    return test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9f5-cBL3Oqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(num_epochs):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "            if (i % 250) == 0:\n",
        "                print(i, \"of\", len(train_loader))\n",
        "\n",
        "            # Move images and labels to gpu if available\n",
        "            if cuda_avail:\n",
        "                images = Variable(images.cuda())\n",
        "                labels = Variable(labels.cuda())\n",
        "\n",
        "            # Clear all accumulated gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Predict classes using images from the test set\n",
        "            outputs = model(images)\n",
        "            # Compute the loss based on the predictions and actual labels\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Adjust parameters according to the computed gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.cpu().item() * images.size(0)\n",
        "            _, prediction = torch.max(outputs.data, 1)\n",
        "            \n",
        "            train_acc += torch.sum(prediction == labels.data)\n",
        "\n",
        "        # Call the learning rate adjustment function\n",
        "        adjust_learning_rate(epoch)\n",
        "\n",
        "        # Compute the average acc and loss over all 50000 training images\n",
        "        train_acc = train_acc / 50000\n",
        "        train_loss = train_loss / 50000\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        test_acc = test()\n",
        "\n",
        "        # Save the model if the test acc is greater than our current best\n",
        "        if test_acc > best_acc:\n",
        "            #save_models(epoch)\n",
        "            best_acc = test_acc\n",
        "\n",
        "        # Print the metrics\n",
        "        print(\"Epoch {}, Train Accuracy: {} , TrainLoss: {} , Test Accuracy: {}\".format(epoch, train_acc, train_loss,test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4sAOf313Oqm",
        "colab_type": "code",
        "outputId": "9b3316cd-e362-41e7-a365-d441dc71892a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "     train(30)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 0, Train Accuracy: 0.4161199927330017 , TrainLoss: 1.56339534866333 , Test Accuracy: 0.5139999985694885\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 1, Train Accuracy: 0.5875599980354309 , TrainLoss: 1.1468429418182373 , Test Accuracy: 0.6074999570846558\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 2, Train Accuracy: 0.6564199924468994 , TrainLoss: 0.96947754529953 , Test Accuracy: 0.6563999652862549\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 3, Train Accuracy: 0.7037599682807922 , TrainLoss: 0.8485816082954407 , Test Accuracy: 0.7195999622344971\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 4, Train Accuracy: 0.737019956111908 , TrainLoss: 0.7635451975631714 , Test Accuracy: 0.729200005531311\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 5, Train Accuracy: 0.7573999762535095 , TrainLoss: 0.7060783775711059 , Test Accuracy: 0.7752000093460083\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 6, Train Accuracy: 0.7760399580001831 , TrainLoss: 0.6595427383136749 , Test Accuracy: 0.7960000038146973\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 7, Train Accuracy: 0.7917400002479553 , TrainLoss: 0.6142466902351379 , Test Accuracy: 0.7967999577522278\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 8, Train Accuracy: 0.8025599718093872 , TrainLoss: 0.5811871588897705 , Test Accuracy: 0.8023999929428101\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 9, Train Accuracy: 0.814300000667572 , TrainLoss: 0.5496173021793366 , Test Accuracy: 0.8018999695777893\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 10, Train Accuracy: 0.8225799798965454 , TrainLoss: 0.5284879102516175 , Test Accuracy: 0.8176999688148499\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 11, Train Accuracy: 0.8312999606132507 , TrainLoss: 0.5015561492919922 , Test Accuracy: 0.8330999612808228\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 12, Train Accuracy: 0.8360199928283691 , TrainLoss: 0.4871825883102417 , Test Accuracy: 0.8093999624252319\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 13, Train Accuracy: 0.8437399864196777 , TrainLoss: 0.4691658309173584 , Test Accuracy: 0.8301999568939209\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 14, Train Accuracy: 0.849399983882904 , TrainLoss: 0.4490508757591248 , Test Accuracy: 0.8424999713897705\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 15, Train Accuracy: 0.8551599979400635 , TrainLoss: 0.42950183087348937 , Test Accuracy: 0.849399983882904\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 16, Train Accuracy: 0.8584799766540527 , TrainLoss: 0.4217528293085098 , Test Accuracy: 0.8374999761581421\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 17, Train Accuracy: 0.8607400059700012 , TrainLoss: 0.411671469707489 , Test Accuracy: 0.852899968624115\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 18, Train Accuracy: 0.8639199733734131 , TrainLoss: 0.40736450909614563 , Test Accuracy: 0.8574000000953674\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 19, Train Accuracy: 0.8676599860191345 , TrainLoss: 0.3899136536550522 , Test Accuracy: 0.8572999835014343\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 20, Train Accuracy: 0.8697399497032166 , TrainLoss: 0.38485975316524507 , Test Accuracy: 0.8610000014305115\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 21, Train Accuracy: 0.8735399842262268 , TrainLoss: 0.3759991655254364 , Test Accuracy: 0.8466999530792236\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 22, Train Accuracy: 0.8769599795341492 , TrainLoss: 0.3659183044362068 , Test Accuracy: 0.8622999787330627\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 23, Train Accuracy: 0.8777199983596802 , TrainLoss: 0.36068948032855985 , Test Accuracy: 0.8593999743461609\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 24, Train Accuracy: 0.880079984664917 , TrainLoss: 0.3549601935577393 , Test Accuracy: 0.8715999722480774\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 25, Train Accuracy: 0.8828799724578857 , TrainLoss: 0.346660019094944 , Test Accuracy: 0.8668999671936035\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 26, Train Accuracy: 0.8850199580192566 , TrainLoss: 0.3415942118692398 , Test Accuracy: 0.8613999485969543\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 27, Train Accuracy: 0.8869199752807617 , TrainLoss: 0.3351051201915741 , Test Accuracy: 0.8666999936103821\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 28, Train Accuracy: 0.8890399932861328 , TrainLoss: 0.3267560265040398 , Test Accuracy: 0.8587999939918518\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 29, Train Accuracy: 0.8890999555587769 , TrainLoss: 0.32840756298542023 , Test Accuracy: 0.8504999876022339\n",
            "CPU times: user 23min 43s, sys: 31.2 s, total: 24min 14s\n",
            "Wall time: 25min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYYG61MZ3Oqo",
        "colab_type": "code",
        "outputId": "3f0f41cd-5fac-4904-9788-bfd3529b5772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Checking GPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('Training on CPU...')\n",
        "else:\n",
        "    print('Training on GPU...')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZobJ65sp3Oqp",
        "colab_type": "code",
        "outputId": "94d01c1d-c105-4cb2-b7da-debb8e890802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYAaixA13Oqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeqJSoFb3Oqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDG6NPgr3Oqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}