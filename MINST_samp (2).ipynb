{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "MINST_samp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKdZlT3f3OqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ53E5cyOjcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbZmaLW_3OqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Unit(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super(Unit,self).__init__()\n",
        "        \n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,kernel_size=3,out_channels=out_channels,stride=1,padding=1)\n",
        "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,input):\n",
        "        output = self.conv(input)\n",
        "        output = self.bn(output)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(SimpleNet,self).__init__()\n",
        "        \n",
        "        #Create 14 layers of the unit with max pooling in between\n",
        "        self.unit1 = Unit(in_channels=3,out_channels=32)\n",
        "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
        "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
        "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit7 = Unit(in_channels=64, out_channels=64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit8 = Unit(in_channels=64, out_channels=128)\n",
        "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit11 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit12 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
        "        \n",
        "        #  make fc a sequential layer and add within softmax and linear \n",
        "\n",
        "        #Add all the units into the Sequential layer in exact order\n",
        "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6\n",
        "                                 ,self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
        "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
        "\n",
        "        self.fc = nn.Linear(in_features=128,out_features=num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.net(input)\n",
        "        output = output.view(-1,128)\n",
        "        output = self.fc(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ5x9Zsg3OqY",
        "colab_type": "code",
        "outputId": "85e2b758-f7a0-489c-fd56-71b2e0fd3b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Define transformations for the training set, flip the images randomly, crop out and apply mean and std normalization\n",
        "train_transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32,padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "#Load the training set\n",
        "train_set =CIFAR10(root=\"./data\",train=True,transform=train_transformations,download=True)\n",
        "\n",
        "#Create a loder for the training set\n",
        "train_loader = DataLoader(train_set,batch_size=32,shuffle=True,num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:04, 41619474.04it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZx5oaJk3Oqb",
        "colab_type": "code",
        "outputId": "955b9cdc-0c7e-42a6-89a1-72ef3a4fdd01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define transformations for the test set\n",
        "test_transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "])\n",
        "\n",
        "# Load the test set, note that train is set to False\n",
        "test_set = CIFAR10(root=\"./data\", train=False, transform=test_transformations, download=True)\n",
        "\n",
        "# Create a loder for the test set, note that both shuffle is set to false for the test loader\n",
        "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM5vbiSb3Oqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "# Check if gpu support is available\n",
        "cuda_avail = torch.cuda.is_available()\n",
        "\n",
        "# Create model, optimizer and loss function\n",
        "model = SimpleNet(num_classes=10)\n",
        "\n",
        "#if cuda is available, move the model to the GPU\n",
        "if cuda_avail:\n",
        "    model.cuda()\n",
        "\n",
        "#Define the optimizer and loss function\n",
        "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX6IHBm03Oqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust_learning_rate(epoch):\n",
        "    lr = 0.001\n",
        "\n",
        "    if epoch > 180:\n",
        "        lr = lr / 1000000\n",
        "    elif epoch > 150:\n",
        "        lr = lr / 100000\n",
        "    elif epoch > 120:\n",
        "        lr = lr / 10000\n",
        "    elif epoch > 90:\n",
        "        lr = lr / 1000\n",
        "    elif epoch > 60:\n",
        "        lr = lr / 100\n",
        "    elif epoch > 30:\n",
        "        lr = lr / 10\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1p_-Dtu3Oqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_models(epoch):\n",
        "    torch.save(model.state_dict(), \"cifar10model_{}.model\".format(epoch))\n",
        "    print(\"Chekcpoint saved\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZXmVNs-3Oqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_acc = 0.0\n",
        "    for i, (images, labels) in enumerate(test_loader):\n",
        "\n",
        "        if cuda_avail:\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "\n",
        "        # Predict classes using images from the test set\n",
        "        outputs = model(images)\n",
        "        _, prediction = torch.max(outputs.data, 1)\n",
        "        \n",
        "        test_acc += torch.sum(prediction == labels.data)\n",
        "\n",
        "    # Compute the average acc and loss over all 10000 test images\n",
        "    test_acc = test_acc / 10000\n",
        "\n",
        "    return test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9f5-cBL3Oqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(num_epochs):\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "            if (i % 250) == 0:\n",
        "                print(i, \"of\", len(train_loader))\n",
        "\n",
        "            # Move images and labels to gpu if available\n",
        "            if cuda_avail:\n",
        "                images = Variable(images.cuda())\n",
        "                labels = Variable(labels.cuda())\n",
        "\n",
        "            # Clear all accumulated gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Predict classes using images from the test set\n",
        "            outputs = model(images)\n",
        "            # Compute the loss based on the predictions and actual labels\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Adjust parameters according to the computed gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.cpu().item() * images.size(0)\n",
        "            _, prediction = torch.max(outputs.data, 1)\n",
        "            \n",
        "            train_acc += torch.sum(prediction == labels.data)\n",
        "\n",
        "        # Call the learning rate adjustment function\n",
        "        adjust_learning_rate(epoch)\n",
        "\n",
        "        # Compute the average acc and loss over all 50000 training images\n",
        "        train_acc = train_acc / 50000\n",
        "        train_loss = train_loss / 50000\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        test_acc = test()\n",
        "\n",
        "        # Save the model if the test acc is greater than our current best\n",
        "        if test_acc > best_acc:\n",
        "            #save_models(epoch)\n",
        "            best_acc = test_acc\n",
        "\n",
        "        # Print the metrics\n",
        "        print(\"Epoch {}, Train Accuracy: {} , TrainLoss: {} , Test Accuracy: {}\".format(epoch, train_acc, train_loss,test_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4sAOf313Oqm",
        "colab_type": "code",
        "outputId": "bbea6b46-af5f-46ca-93ae-3494bdc80e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "     train(30)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 0, Train Accuracy: 0.43643999099731445 , TrainLoss: 1.5148291731643677 , Test Accuracy: 0.5651000142097473\n",
            "0 of 1563\n",
            "250 of 1563\n",
            "500 of 1563\n",
            "750 of 1563\n",
            "1000 of 1563\n",
            "1250 of 1563\n",
            "1500 of 1563\n",
            "Epoch 1, Train Accuracy: 0.6024199724197388 , TrainLoss: 1.1133498499298096 , Test Accuracy: 0.6327999830245972\n",
            "CPU times: user 1min 59s, sys: 9.94 s, total: 2min 8s\n",
            "Wall time: 2min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYYG61MZ3Oqo",
        "colab_type": "code",
        "outputId": "d0c3d5d2-8e4a-48c1-a7ad-47f1676136c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Checking GPU is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('Training on CPU...')\n",
        "else:\n",
        "    print('Training on GPU...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZobJ65sp3Oqp",
        "colab_type": "code",
        "outputId": "cf908438-6d55-4dcd-9ab1-13f181580c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.is_available()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYAaixA13Oqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeqJSoFb3Oqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDG6NPgr3Oqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}